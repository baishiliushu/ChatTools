import asyncio
import os
import json
import sys
import time

import aiohttp
from typing import Optional, List, Dict, Any
from contextlib import AsyncExitStack

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.client.sse import sse_client
from mcp.client.streamable_http import streamablehttp_client as shttp_client
from dotenv import load_dotenv
import logging
import httpx
from urllib.parse import urlparse

# Load .env
load_dotenv()
logger = logging.getLogger("terminal_client")
logging.basicConfig(level=logging.DEBUG)

class LocalMCPClient:
    def __init__(self, prompt_file_path = "prompt.txt"):
        self.exit_stack = AsyncExitStack()
        self.vllm_api_url = os.getenv("VLLM_API_URL", "http://192.168.50.208:8000/v1/chat/completions")
        self.model_name = os.getenv("MODEL_NAME", "QwQ-32B-AWQ")
        self.vllm_api_key = os.getenv("VLLM_API_KEY", "mindo")
        with open(prompt_file_path, "r", encoding="utf-8") as f:
            self.file_content = f.read()

        self.mcp_session: Optional[ClientSession] = None
        self.mcp_tools: list = []
        self.http_session: Optional[aiohttp.ClientSession] = None
        self.chat_history: List[Dict[str, Any]] = []
        self.test_queries = [
            "è®¾å¤‡indemind, ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ",
            "è®¾å¤‡indemind, è¯·ä½ å›åˆ°å……ç”µæ¡©å¾…å‘½",
            "è®¾å¤‡indemind, å¾€å‰èµ°ä¸¤ç±³",
            "è®¾å¤‡indemind, è¯·å¸®æˆ‘æ‰¾ä¸€ä¸‹å®¢å…çš„çŒ«",
            "è®¾å¤‡indemind, å»å§å®¤é è¿‘ä¸€ä¸‹åƒåœ¾æ¡¶",
            "è®¾å¤‡indemind, è¯·è¿›è¡Œä¸€æ¬¡å…¨å±‹çš„å·¡é€»æ£€æŸ¥",
            "è®¾å¤‡indemind, å…ˆå»ä¹¦æˆ¿æ‰¾ä¸€ä¸‹æ’æ’ï¼Œç„¶åå›åˆ°å……ç”µæ¡©",
            "è®¾å¤‡indemind, å…ˆå»å§å®¤æ‰¾ä¸€ä¸‹åƒåœ¾æ¡¶ï¼Œæ‰¾åˆ°åå†å»å®¢å…æ‰¾ç”µè§†ï¼Œç„¶åå›æ¡©"
        ]
        self.mcp_mode = os.getenv("MCP_MODE_BY_URL", "mcp_server.py")  # stdio, sse, shttp

    async def initialize_http_session(self):
        if not self.http_session:
            self.http_session = aiohttp.ClientSession()
            await self.exit_stack.enter_async_context(self.http_session)

    async def connect_to_mcp_server(self, server_script_path: str):
        if not os.path.isfile(server_script_path):
            raise FileNotFoundError(f"MCP Server è„šæœ¬æœªæ‰¾åˆ°: {server_script_path}")

        print(f"å°è¯•è¿æ¥åˆ° MCP Server è„šæœ¬: {server_script_path}...")
        command = "python" if server_script_path.endswith('.py') else "node"

        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=os.environ.copy()
        )

        try:
            stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
            stdio_reader, stdio_writer = stdio_transport
            self.mcp_session = ClientSession(stdio_reader, stdio_writer)
            await self.exit_stack.enter_async_context(self.mcp_session)

            await self.mcp_session.initialize()
            response = await self.mcp_session.list_tools()
            self.mcp_tools = response.tools
            if not self.mcp_tools:
                print("âš ï¸ MCP Server æœªæŠ¥å‘Šä»»ä½•å¯ç”¨å·¥å…·ã€‚")
            else:
                print("âœ… å·²è¿æ¥åˆ° MCP Serverï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in self.mcp_tools])

        except Exception as e:
            print(f"âŒ è¿æ¥åˆ° MCP Server å¤±è´¥: {e}")
            raise

    def convert_mcp_tools_to_openai_format(self) -> List[Dict[str, Any]]:
        tools_openai_format = []
        for tool in self.mcp_tools:
            schema = tool.schema if hasattr(tool, 'schema') and isinstance(tool.schema, dict) else {"type": "object", "properties": {}, "required": []}
            tools_openai_format.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": schema
                }
            })
        return tools_openai_format

    async def call_vllm_api(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None) -> Optional[Dict[str, Any]]:
        if not self.http_session:
            await self.initialize_http_session()

        payload = {
            "model": self.model_name,
            "messages": messages,
            #"max_tokens": 90000,
            "temperature": 0.5,
        }

        if tools:
            try:
                json.dumps(tools)  # Test serialization
                payload["tools"] = tools
                payload["tool_choice"] = "auto"
            except TypeError as e:
                print(f"âŒ å·¥å…·åºåˆ—åŒ–å¤±è´¥: {e}")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.vllm_api_key}"
        }

        print(f"ğŸ”„ æ­£åœ¨å‘ vLLM å‘é€è¯·æ±‚ ({self.vllm_api_url})...")
        try:
            time_start_f = time.time()
            async with self.http_session.post(self.vllm_api_url, headers=headers, json=payload, timeout=300) as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"ğŸ” åŸå§‹ vLLM å“åº”:\n{json.dumps(result, indent=2, ensure_ascii=False)}\n")
                    time_end_f = time.time()
                    print("è·å–åŸå§‹vLLM å“åº” time cost: {:.2f} s".format(time_end_f - time_start_f))
                    return result
                else:
                    error_text = await response.text()
                    print(f"âŒ vLLM API è¯·æ±‚å¤±è´¥ã€‚çŠ¶æ€ç : {response.status}")
                    print(f"å“åº”å†…å®¹: {error_text[:1000]}...")
                    return None

        except Exception as e:
            print(f"âŒ è°ƒç”¨ vLLM API æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
            return None

    async def process_query(self, query: str) -> Optional[str]:
        
        if not self.http_session:
            await self.initialize_http_session()
        querrys = query.split("c+++")
        if query.startswith("c+++") or len(self.chat_history) > 15:
            #self.chat_history = []
            await self.clear_chat_history()
        query = querrys[-1]
        if len(query) < 1:
            return "EMPTY user words."
        print(f"å‘é€è¯·æ±‚åˆ°æ¨¡å‹: {query}")
        system_message = {"role": "system", "content": self.file_content}
        messages = [system_message] + self.chat_history + [{"role": "user", "content": query}]
        tools_for_llm = self.convert_mcp_tools_to_openai_format()
        #print("openai mesages:\n{}".format(tools_for_llm))
        llm_response_data = await self.call_vllm_api(messages, tools=tools_for_llm)

        if not llm_response_data:
            return "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ€è€ƒæ—¶é‡åˆ°äº†ä¸€äº›éº»çƒ¦ã€‚"
        if llm_response_data.get("choices"):
                                                                                            
            choice = llm_response_data["choices"][0]
            message = choice["message"]
            #delta = choice.get('content', {})
            content = message.get("content")
            tool_calls = message.get("tool_calls")
            if tool_calls:
                toll_index = 0
                tool_name_contents = list()
                tool_name_description = ""
                tool_content_description = ""
                
                for toll_index in range(0, len(tool_calls)):
                    tool_call = tool_calls[toll_index]
                    tool_name = tool_call['function']['name']
                    tool_args = json.loads(tool_call['function']['arguments'])

                    print(f"ğŸ› ï¸ çœŸå® ToolCall: {tool_name}, å‚æ•°: {tool_args}")
                    mcp_result = await self.mcp_session.call_tool(tool_name, tool_args)
                    tool_content = mcp_result.content[0].text if mcp_result.content else "å·¥å…·æœªè¿”å›ä»»ä½•å†…å®¹ã€‚"
                    tool_name_contents.append({"tool_name":tool_name, "tool_content":tool_content})
                
                for tc in tool_name_contents:
                    tool_name_description = tool_name_description + ";" + tc["tool_name"]
                    tool_content_description = tool_content_description + ";" + tc["tool_content"]

                tool_result_msg = {
                        "role": "user",
                        "content": f"å·¥å…· '{tool_name_description}' æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›ï¼š\n{tool_content_description}\nè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š'{query}'"
                    }    
                self.chat_history.extend([{"role": "user", "content": query}, message, tool_result_msg])

                final_response = await self.call_vllm_api([system_message] + self.chat_history)
                if final_response and final_response.get("choices"):
                    final_content = final_response["choices"][0]["message"].get("content")
                    self.chat_history.append({"role": "assistant", "content": final_content})
                    return final_content    
                else:
                    return "æŠ±æ­‰ï¼Œå¤„ç†å·¥å…·ç»“æœæ—¶å‡ºé”™ã€‚" # è®¾å¤‡ b0:ac:82:47:d0:1d ,å·¦è½¬2åº¦å†è½¬å›æ¥

            else:
                llm_content = message.get("content", "").strip()
                self.chat_history.extend([{"role": "user", "content": query}, message])
                return llm_content       
                                                           
    async def clear_chat_history(self):
        l = len(self.chat_history)
        self.chat_history = []
        print("\nå·²æ¸…ç©ºï¼ˆ{}æ¡ï¼‰ä¼šè¯å†å²".format(l))
        return len(self.chat_history)
        
    async def chat_loop(self):
        print("\nğŸ¤– æœ¬åœ° LLM + MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")
        while True:
            try:
                query = input("\nä½ : ").strip()
                if not query:
                    continue
                if query.lower() == 'quit' or query.lower() == 'q':
                    break
                if query.lower() == 'ttt':
                    await self.run_batch_test()
                if  query.lower() == 'c':
                    await self.clear_chat_history()
                else:
                    response_text = await self.process_query(query)
                    print(f"\nğŸ¤– Assistant: {response_text}")
            except KeyboardInterrupt:
                print("\næ£€æµ‹åˆ°ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
                break
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")


    async def run_batch_test(self):
        system_message = {"role": "system", "content": self.file_content}
        tools_for_llm = self.convert_mcp_tools_to_openai_format()

        stats = []

        for i, query in enumerate(self.test_queries):
            messages = [system_message, {"role": "user", "content": query}]
            print(f"\nğŸ§ª æµ‹è¯• {i+1}/{len(self.test_queries)}: {query}")

            start = time.time()
            result = await self.call_vllm_api(messages, tools=tools_for_llm)
            end = time.time()

            duration = end - start
            stats.append((query, duration))
            print(f"ğŸ•’ å“åº”è€—æ—¶: {duration:.2f} ç§’\n")

        print("\nğŸ“Š æ‰¹é‡æµ‹è¯•å®Œæˆï¼\n")
        for query, duration in stats:
            print(f"ã€{query}ã€‘è€—æ—¶: {duration:.2f} ç§’")

        all_times = [d for _, d in stats]
        print(f"\nğŸ“ˆ å¹³å‡è€—æ—¶: {sum(all_times)/len(all_times):.2f} ç§’")
        print(f"â±ï¸ æœ€å¿«: {min(all_times):.2f} ç§’ï¼Œæœ€æ…¢: {max(all_times):.2f} ç§’")


    async def cleanup(self):
        print("æ­£åœ¨å…³é—­è¿æ¥...")
        await self.exit_stack.aclose()
        print("è¿æ¥å·²å…³é—­ã€‚")

    
    async def _connect_stdio(self, server_script_path: str):
        """ä½¿ç”¨stdioæ¨¡å¼è¿æ¥"""
        if not os.path.isfile(server_script_path):
            raise FileNotFoundError(f"MCP Server è„šæœ¬æœªæ‰¾åˆ°: {server_script_path}")

        command = "python" if server_script_path.endswith('.py') else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=os.environ.copy()
        )

        try:
            stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
            stdio_reader, stdio_writer = stdio_transport
            self.mcp_session = ClientSession(stdio_reader, stdio_writer)
            await self._initialize_session()
        except Exception as e:
            print(f"âŒ ä½¿ç”¨ stdio æ¨¡å¼è¿æ¥åˆ° MCP Server å¤±è´¥: {e}")
            raise

    async def _connect_sse(self, sse_url: str):
        """ä½¿ç”¨SSEæ¨¡å¼è¿æ¥ urlé»˜è®¤ http://192.168.50.222:8087/sse"""
        try:
            os.environ.pop('ALL_PROXY', None)
            os.environ.pop('all_proxy', None)
                
            sse_transport = await self.exit_stack.enter_async_context(sse_client(sse_url))
            sse_reader, sse_writer = sse_transport
            self.mcp_session = ClientSession(sse_reader, sse_writer)
            await self._initialize_session()
        except Exception as e:
            print(f"âŒ ä½¿ç”¨ SSE æ¨¡å¼è¿æ¥åˆ° MCP Server å¤±è´¥: {e} BY {sse_url}")
            raise

    async def _connect_shttp(self, shttp_url: str):
        """ä½¿ç”¨sHTTPæ¨¡å¼è¿æ¥"""
        try:
            os.environ.pop('ALL_PROXY', None)
            os.environ.pop('all_proxy', None)
            shttp_transport = await self.exit_stack.enter_async_context(shttp_client(shttp_url))
            shttp_reader = None
            shttp_writer = None
            shttp_get_session_id = None
            if len(shttp_transport) > 1:
                shttp_reader, shttp_writer, shttp_get_session_id = shttp_transport
                #if rest:
                    #print(f"[DDDD] Additional elements: {rest}")
                    #shttp_get_session_id = rest[0]
                    #exit(8)
            else:
                exit(-3)
            self.mcp_session = ClientSession(shttp_reader, shttp_writer)
            await self._initialize_session()
        except Exception as e:
            print(f"âŒ ä½¿ç”¨ sHTTP æ¨¡å¼è¿æ¥åˆ° MCP Server å¤±è´¥: {e}")
            raise

    async def connect_to_mcp(self):
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨ï¼Œæ”¯æŒä¸‰ç§æ¨¡å¼"""
        print(f"å°è¯•ä½¿ç”¨ {self.mcp_mode.upper()} æ¨¡å¼è¿æ¥åˆ° MCP æœåŠ¡å™¨...")
        mcp_mode_by_url = self.mcp_mode
        if ".py" in  mcp_mode_by_url:
            await self._connect_stdio(mcp_mode_by_url)
        elif "sse" in  mcp_mode_by_url:
            await self._connect_sse(mcp_mode_by_url)
        elif "shttp" in  mcp_mode_by_url:
            await self._connect_shttp(mcp_mode_by_url)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ MCP æ¨¡å¼: {self.mcp_mode}")

    async def _initialize_session(self):
        """åˆå§‹åŒ–MCPä¼šè¯"""
        await self.exit_stack.enter_async_context(self.mcp_session)
        await self.mcp_session.initialize()
        response = await self.mcp_session.list_tools()
        self.mcp_tools = response.tools
        
        if not self.mcp_tools:
            print("âš ï¸ MCP Server æœªæŠ¥å‘Šä»»ä½•å¯ç”¨å·¥å…·ã€‚")
        else:
            print("âœ… å·²è¿æ¥åˆ° MCP Serverï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in self.mcp_tools])


async def main():
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_prompt>")
        sys.exit(1)

    prompt_txt_path = sys.argv[1]
    client = LocalMCPClient(prompt_txt_path)
    try:
        await client.initialize_http_session()
        #await client.connect_to_mcp_server(mcp_server_script)
      
        await client.connect_to_mcp()
        await client.chat_loop()

    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())

